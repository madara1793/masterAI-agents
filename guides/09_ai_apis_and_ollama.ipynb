{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM APIs and Ollama\n",
    "\n",
    "## Introduction to APIs\n",
    "\n",
    "Throughout the course, we use APIs for connecting with the strongest LLMs on the planet.\n",
    "\n",
    "You can switch LLMs and pick different ones at any point; you may need to look up in the framework docs how best to switch to a different API, or ask me.\n",
    "\n",
    "OpenAI has a python client library which simplifies the way we call OpenAI on the cloud:\n",
    "\n",
    "```\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=[{\"role\":\"user\", \"content\":\"what is 2+2?\"}])\n",
    "print(response.choices[0].message.content)\n",
    "```\n",
    "\n",
    "Several other LLMs, including Google Gemini and DeepSeek, have API endpoints that are compatible with OpenAI.\n",
    "\n",
    "OpenAI has made their python client library available for others to use by switching the URL from their URL to somewhere else:\n",
    "\n",
    "`not_actually_openai = OpenAI(base_url=\"https://somewhere.completely.different/\", api_key=\"another_providers_key\")`\n",
    "\n",
    "It's important to realize that this OpenAI code is just a utility for making https calls to endpoints. There's no LLM code here - just a wrapper around a network call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Costs of APIs\n",
    "\n",
    "The cost of each API call is very low indeed - most calls to models we use on this course are fractions of cents.\n",
    "\n",
    "But it's extremely important to note:\n",
    "\n",
    "1. With Agentic AI, there is a risk of Agents getting into a loop or carrying out more processing than intended. You should monitor your API usage, and never put more budget than you are comfortable with. Some APIs have an \"auto-refill\" setting that can charge automatically to your card - I strongly recommend you keep this off.\n",
    "\n",
    "2. You should only spend what you are comfortable with. There is a free alternative in Ollama that you can use as a replacement if you wish. DeepSeek, Gemini 2.5 Flash and gpt-4.1-nano are significantly cheaper.\n",
    "\n",
    "Keep in mind that these LLM calls typically involve trillions of floating point calculations - someone has to pay the electricity bills!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ollama: Free alternative to Paid APIs (but please see Warning about llama version)\n",
    "\n",
    "Ollama is a product that runs locally on your machine. It can run open-source models, and it provides an API endpoint on your computer that is compatible with OpenAI.\n",
    "\n",
    "First, download Ollama by visiting:\n",
    "https://ollama.com\n",
    "\n",
    "Then from your Terminal in Cursor (View menu >> Terminal), run this command to download a model:\n",
    "\n",
    "`ollama pull llama3.2`\n",
    "\n",
    "Be careful not to use llama3.3 or llama4 - these are much larger models that are not suitable for home computers.\n",
    "\n",
    "And now, any time that we have code like:  \n",
    "`openai = OpenAI()`  \n",
    "You can use this as a direct replacement:  \n",
    "`openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "And also replace model names like **gpt-4o-mini** with **llama3.2**.  \n",
    "\n",
    "Below is a full example:\n",
    "\n",
    "```\n",
    "# You need to do this one time on your computer\n",
    "!ollama pull llama3.2\n",
    "\n",
    "from openai import OpenAI\n",
    "MODEL = \"llama3.2\"\n",
    "openai = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    " model=MODEL,\n",
    " messages=[{\"role\": \"user\", \"content\": \"What is 2 + 2?\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "```\n",
    "\n",
    "You will need to make similar changes to use Ollama within any of the Agent Frameworks - you should be able to google for an exact example, or ask me."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
